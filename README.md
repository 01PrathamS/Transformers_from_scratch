# Transformers_from_scratch

1. Embeddings: representing text in lower dimensional representation.
   converting text into numerical : learnable parameter.

2. Positional Embedding: Convey positional information to the model
   Sin function: Even position of embedding
   cos function: odd position of embedding
   stays the same : nonlearnable parameter.

3. Attention Mechanism:


## Resources 
--> Umer Jahil: Tranfomers from scratch
--> Analytics Vidhya: Transformers from scratch
--> Stanford Online: Transformers United Series 
--> Andrej Karpathy: Neural Network Zero to Hero: Build GPT
